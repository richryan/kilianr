---
title: "Structural VAR Models Using Recursive Identification"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Structural VAR Models Using Recursive Identification}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

Here are some useful functions that can be used to analyze 
structural vector autoregressive models or
structural VAR models.
In particular,
the functions go through estimating a recursively identified model.
A prime example of this method is used by Lutz Kilian in

> Kilian, Lutz. 2009. "Not All Oil Price Shocks Are Alike: Disentangling Demand and Supply Shocks in the Crude Oil Market." American Economic Review, 99 (3): 1053–69. DOI: 10.1257/aer.99.3.1053

Functions in the package `kilianr` can:

1. Estimate a VAR model by unrestricted least squares
1. Identify models using Cholesky decompositions
1. Compute confidence sets for these estimators

Good background reading includes

- Kilian, Lutz, and Helmut Lütkepohl. Structural Vector Autoregressive Analysis. Cambridge: Cambridge University Press, 2017.
- Helmut Lütkepohl. New Introduction to Multiple Time Series Analysis. Berlin: Springer, 2005.


In fact,
you could think about this package as an extended advertisement for those resources.
And purchasing a copy of 
[*Structural Vector Autoregressive Analysis*](https://www.cambridge.org/core/books/structural-vector-autoregressive-analysis/DAF4217439EA585D10902D58A8849E06)
is recommended.

## Least-squares estimation

Interest is in $K$ time-series variables.
For example, quarterly US data on
the rate of price inflation,
the unemployment rate, and
the interest rate---in which case, $K=3$.^[Which is the system analyzed by Stock and Watson. See: Stock, James, H., and Mark W. Watson. 2001. "Vector Autoregressions." Journal of Economic Perspectives, 15 (4): 101--115. DOI: 10.1257/jep.15.4.101.]
The time series can be represented as
$$
y_{t}=\left(y_{1t},\dots,y_{Kt}\right)^{\prime}.
$$
The data generating process is posited to follow a linear VAR process of order $p$,
often written as VAR($p$).
Which means the statistical model for $y_t$ can be written as 
$$
y_{t}=\nu+A_{1}y_{t-1}+\cdots+A_{p}y_{t-p}+u_{t},
$$
where 

- the vector $\nu=\left(\nu_{1},\dots,\nu_{K}\right)^{\prime}$ is a $\left(K\times1\right)$ vector of intercept terms,
- the $A_i$, $i=1,\dots,p$, are $K \times K$ parameter matricies, and
- the vector $u_t = \left( u_{1t},\dots,u_{Kt} \right)^{\prime}$ is a $K$-dimensional zero-mean white-noise process; that is, $u_t$ is assumed to be iid white noise with nonsingular covariance matrix $\Sigma_u$, $u_t \overset{\text{iid}}{\sim} \left( 0, \Sigma_u \right)$.

Under some common regularity assumptions discussed by Kilian and Lütkepohl,
the model can be estimated by least squares efficiently.

### Empirical demonstration of LS estimation

The functions in kilianr can easily produce LS estimates.
This example comes from section 2.3 of [*Structural Vector Autoregressive Analysis*](https://www.cambridge.org/core/books/structural-vector-autoregressive-analysis/DAF4217439EA585D10902D58A8849E06).

The empirical demonstration uses quarterly US data on
real GNP growth,
the federal funds rate, and
inflation measured using the GNP deflator.
These data are included in `kilianLutkepohlCh02Macro`.

```{r}
library(dplyr)
library(kilianr)
library(ggplot2)
library(patchwork)

plt_rgnp <- ggplot(data = kilianLutkepohlCh02Macro) +
  geom_line(mapping = aes(x = date, y = drgnp)) +
  labs(x = "", y = "", title= "Real GNP growth")

plt_ffr <- ggplot(data = kilianLutkepohlCh02Macro) +
  geom_line(mapping = aes(x = date, y = irate)) +
  labs(x = "", y = "", title= "Federal funds rate")

plt_infl <- ggplot(data = kilianLutkepohlCh02Macro) +
  geom_line(mapping = aes(x = date, y = infl)) +
  labs(x = "", y = "", title= "GNP deflator inflation")

# Using notation from the patchwork package to combine figures
plt_rgnp / plt_ffr / plt_infl
```

The VAR($4$) model for $y_t = \left( \Delta \text{GNP}_t, \text{interest rate}_t, \Delta \text{price}_t \right)$ can be estimated by LS using the code show below.
The function `olsvarc` includes a constant.
```{r setup}
y <- kilianLutkepohlCh02Macro |> select(drgnp, irate, infl)
sol <- olsvarc(y, p = 4)
```

The code can be checked against the estimates show on page 33 of
[*Structural Vector Autoregressive Analysis*](https://www.cambridge.org/core/books/structural-vector-autoregressive-analysis/DAF4217439EA585D10902D58A8849E06).
The following block of code prints out the LS estimates.
Here are the LS estimates, $\hat{\nu}$:
```{r}
print(round(sol$Vhat, 4))
```

And the LS estimates, $\hat{A}_1, \dots, \hat{A}_4$:
```{r}
KK <- 3
pp <- 4
for (i in 1:pp) {
  # The A_i hats have indices 1--K, (K+1)--2K, (2K+1)--3K, ...
  # 1-3, 4-6, 7-9
  print(paste0("A_", i, ": "))
  print(round(sol$Ahat[, ((i - 1) * KK + 1):(i * KK)], 4))
}
```

A consistent estimator of $\Sigma_u$ under the above assumptions, $\widehat{\Sigma}_u$,
is expressed in equation (2.3.4), page 31, of [*Structural Vector Autoregressive Analysis*](https://www.cambridge.org/core/books/structural-vector-autoregressive-analysis/DAF4217439EA585D10902D58A8849E06).
The estimate is
```{r}
print(round(sol$SIGMAhat, 4))
```

These values agree with those found on page 34 for this example.

## Using short-run identification restrictions to recursively identify models: Cholesky decomposition

A structural VAR identifies correlations among variables using economic theory.
The identifying assumptions allow the correlations to be interpreted causally.

The $K$-dimensional structural VAR($p$) model is
$$
B_{0}y_{t}=B_{1}y_{t-1}+\cdots+B_{p}y_{t-p}+w_{t},
$$
where $w_t \sim \left( 0, \Sigma_w \right)$ are the structural errors.
The structural errors have a diagonal covariance matrix $\Sigma_w$ and are serially uncorrelated. 
The corresponding reduced form is
$$
\begin{align*}
y_{t}	&=\underbrace{B_{0}^{-1}B_{1}}_{A_{1}}y_{t-1}+\cdots+\underbrace{B_{0}^{-1}B_{p}}_{A_{p}}y_{t-p}+\underbrace{B_{0}^{-1}w_{t}}_{u_{t}} \\
	&=A_{1}y_{t-1}+\cdots+A_{p}y_{t-p}+u_{t}.
\end{align*}
$$
Going from the reduced-form to structural representation requires knowledge of $B_0^{-1}$.
The structural representation offers a causal interpretation of the correlations uncovered by the model.

Recursive identificaiton is one of the most straightforward ways to identify a VAR model.
This method decomposes $\widehat{\Sigma}_u$ using the Cholesky decomposition.
Kilian and Lütkepohl discuss this approach in chapter 9 of [*Structural Vector Autoregressive Analysis*](https://www.cambridge.org/core/books/structural-vector-autoregressive-analysis/DAF4217439EA585D10902D58A8849E06).
This example comes from that chapter discussed around figure 9.1,
which is found on page 244.

To confirm the reduced-form parameter estimates,
the following code shows LS estimates 

```{r}
y_macro_oil <- kilianLutkepohlCh09Figure9_1 |> select(drpoil, infl, drgdp)
sol_macro_oil <- olsvarc(y_macro_oil, p = 4)

KK <- 3
pp <- 4
for (i in 1:pp) {
  # The A_i hats have indices 1--K, (K+1)--2K, (2K+1)--3K, ...
  # 1-3, 4-6, 7-9
  print(paste0("A_", i, ": "))
  print(round(sol_macro_oil$Ahat[, ((i - 1) * KK + 1):(i * KK)], 4))
}
```
The residual variance--covariance matrix $\widehat{\Sigma}_u$ is
```{r}
print(round(sol_macro_oil$SIGMAhat, 4))
```

These estimates agree with those reported on page 243.

The estimated $\text{chol} \left( \widehat{\Sigma}_u \right)$ is

```{r}
B0inv <- t(chol(sol_macro_oil$SIGMAhat))
print(round(B0inv, 4))
```
The decomposition is such that $\text{chol} \left( \widehat{\Sigma}_u \right) = \widehat{B}_0^{-1}$ and
$\left( \widehat{B}_0^{-1} \right) \left( \widehat{B}_0^{-1} \right)^{\prime} = \widehat{\Sigma}_u$.

This agrees with the numbers reported on page 244.

```{r}
horizon <- 12
irf_macro_oil <- irfvar(sol_macro_oil$Ahat, B0inv, p = sol_macro_oil$p, h = horizon)
```

## Empirical application: Kilian's "Not all oil price shocks are alike"

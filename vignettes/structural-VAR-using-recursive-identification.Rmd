---
title: "Structural VAR Models Using Recursive Identification"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Structural VAR Models Using Recursive Identification}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

Here are some useful functions that can be used to analyze 
structural vector autoregressive models or
structural VAR models.
In particular,
the functions go through estimating a recursively identified model.
A prime example of this method is used by Lutz Kilian in

> Kilian, Lutz. 2009. "Not All Oil Price Shocks Are Alike: Disentangling Demand and Supply Shocks in the Crude Oil Market." American Economic Review, 99 (3): 1053–69. DOI: 10.1257/aer.99.3.1053

Functions in the package `kilianr` can:

1. Estimate a VAR model by unrestricted least squares
1. Identify models using Cholesky decompositions
1. Compute confidence sets for these estimators

Good background reading includes

- Kilian, Lutz, and Helmut Lütkepohl. Structural Vector Autoregressive Analysis. Cambridge: Cambridge University Press, 2017.
- Helmut Lütkepohl. New Introduction to Multiple Time Series Analysis. Berlin: Springer, 2005.


In fact,
you could think about this package as an extended advertisement for those resources.

## Least-squares estimation

Interest is in $K$ time-series variables.
For example, quarterly US data on
the rate of price inflation,
the unemployment rate, and
the interest rate---in which case, $K=3$.^[Which is the system analyzed by Stock and Watson. See: Stock, James, H., and Mark W. Watson. 2001. "Vector Autoregressions." Journal of Economic Perspectives, 15 (4): 101--115. DOI: 10.1257/jep.15.4.101.]
The time series can be represented as
$$
y_{t}=\left(y_{1t},\dots,y_{Kt}\right)^{\prime}.
$$
The data generating process is posited to follow a linear VAR process of order $p$,
often written as VAR($p$).
Which means the statistical model for $y_t$ can be written as 
$$
y_{t}=\nu+A_{1}y_{t-1}+\cdots+A_{p}y_{t-p}+u_{t},
$$
where 

- the vector $\nu=\left(\nu_{1},\dots,\nu_{K}\right)^{\prime}$ is a $\left(K\times1\right)$ vector of intercept turns,
- the $A_i$, $i=1,\dots,p$, are $K \times K$ parameter matricies, and
- the vector $u_t = \left( u_{1t},\dots,u_{Kt} \right)^{\prime}$ is a $K$-dimensional zero-mean white-noise process; that is, $u_t$ is assumed to be iid white noise with nonsingular covariance matrix $\Sigma_u$, $u_t \overset{\text{iid}}{\sim} \left( 0, \Sigma_u \right)$.

Under some common regularity assumptions discussed by Kilian and Lütkepohl,
the model can be estimated by least squares efficiently.

### Empirical demonstration of LS estimation

The functions in kilianr can easily produce LS estimates.
This example comes from section 2.3 of [*Structural Vector Autoregressive Analysis*](https://www.cambridge.org/core/books/structural-vector-autoregressive-analysis/DAF4217439EA585D10902D58A8849E06).

The empirical demonstration uses quarterly US data on
real GNP growth,
the federal funds rate, and
inflation measured using the GNP deflator.
These data are included in `kilianLutkepohlCh02Macro`.
The VAR($4$) model for $y_t = \left( \Delta \text{GNP}_t, \text{interest rate}_t, \Delta \text{price}_t \right)$ can be estimated by LS using the code show below.
The function `olsvarc` includes a constant.
```{r setup}
library(dplyr)
library(kilianr)

y <- kilianLutkepohlCh02Macro |> select(drgnp, irate, infl)
sol <- olsvarc(y, p = 4)
```

The code can be checked against the estimates show on page 33 of
[*Structural Vector Autoregressive Analysis*](https://www.cambridge.org/core/books/structural-vector-autoregressive-analysis/DAF4217439EA585D10902D58A8849E06).
The following block of code prints out the LS estimates.
Here are the LS estimates, $\hat{\nu}$:
```{r}
print(round(sol$Vhat, 4))
```

And the LS estimates, $\hat{A}_1, \dots, \hat{A}_4$:
```{r}
KK <- 3
pp <- 4
for (i in 1:pp) {
  # The A_i hats have indices 1--K, (K+1)--2K, (2K+1)--3K, ...
  # 1-3, 4-6, 7-9
  print(paste0("A_", i, ": "))
  print(round(sol$Ahat[, ((i - 1) * KK + 1):(i * KK)], 4))
}
```

A consistent estimator of $\Sigma_u$ under the above assumptions, $\widehat{\Sigma}_u$,
is expressed in equation (2.3.4), page 31, of [*Structural Vector Autoregressive Analysis*](https://www.cambridge.org/core/books/structural-vector-autoregressive-analysis/DAF4217439EA585D10902D58A8849E06).
The estimate is
```{r}
print(round(sol$SIGMAhat, 4))
```

These values agree with those found on page 34 for this example.

## Using short-run identification restrictions to recursively identify models

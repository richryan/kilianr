---
title: "inference-with-moving-block-bootstrap"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{inference-with-moving-block-bootstrap}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: references.bib  
link-citations: TRUE
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(kilianr)
```

To render the vignette:
devtools::build_rmd("vignettes/inference-with-moving-block-bootstrap.Rmd")

# Introduction

The procedure is discussed by @kilian_lutkepohl_2017 on
pages 355--356 in chapter 12, "Inference."

The mechanics of the moving block boostrap can be seen
by looking at how the error matrix is constructed.

The data are fit to the VAR($p$) model
$$
y_t = \nu + A_1 y_{t-1} + \cdots + A_p y_{t-p} + u_t,
$$
where $u_t$ is serially uncorrelated but **conditionally heteroskedastic**.
After estimating the model parameters,
the estimated model residuals are computed as
$$
 \widehat{u}_t = y_t - \widehat{\nu} - \widehat{A}_1 y_{t-1} - \cdots - \widehat{A}_p y_{t-p} \text{ for } t=1,\dots,T.
$$

The aim is resampling the estimated residuals.
A block of length $l < T$ is chosen.
The number of blocks is $s = \lceil T / l \rceil$
where $s$ denotes the smallest integer larger or equal to $T / l$ so that
$s \geq T / l$ or $sl \geq T$.
The last inequality says that number of blocks times the length of each block is greater than $T$.

"Bootstrap innovations are generated by drawing $s$ time with replacement
from the rows" of the matrix
$$
\begin{bmatrix}
\widehat{u}_1 & \widehat{u}_2 & \dots & \widehat{u}_l \\
\widehat{u}_2 & \widehat{u}_3 & \dots & \widehat{u}_{1+l} \\
\vdots        & \vdots        & \vdots& \vdots \\
\widehat{u}_{T-l+1} & \widehat{u}_{T-l+2} & \dots & \widehat{u}_{T} \\
\end{bmatrix}
$$
The blocks are concatenated and the first $T$ boostrap innovations are kept.
*Note*: the boostrap-innovation draws must be recentered so that
$E \left[ u_t^* \right] = 0$ for all $t=1,\dots,T$.

The bootstrap sample $\left[ y_{-p+1}^*,\dots,y_{T}^*\right]$ is generated
recursively using
$$
y_t^* = \widehat{\nu} + \widehat{A}_1 y_{t-1}^* + \cdots + \widehat{A}_p y_{t-p}^*.
$$

# Mechanics of moving block bootstrap in R

The series of bootstrap innovations $\left[ u_1^*, \dots, u_T^* \right]$ 
can be constructed in R as follows. 

The application considered below is the global market for oil [@kilian_2009].
The VAR($p = 24$) model comprises data on 
oil production, global real economic activity, and the real price of oil.
Instead of using these data, though,
the code chunk below 
generates blocks of *dates* to show how the blocks of estimated innovations are constructed.

The following code chunk generates the date strings:
```{r}
library(dplyr)
# Create data to look through
yview <- kilianLutkepohlCh12Figure12_5 |> 
  mutate(date_prefix = paste0(lubridate::year(date), "-", format(date, "%m")),
         oil_supply = paste0(date_prefix, "-", "oilsupply"),
         agg_demand = paste0(date_prefix, "-", "aggdemand"),
         rpoil = paste0(date_prefix, "-", "rpoil")) |> 
  select(oil_supply, agg_demand, rpoil)
head(yview)
```

```{r}
tail(yview)
```

Instead of numeric data,
data consist of a date and the associated series.
(The data do not start in January 2023 because variable for oil supply measures
the change in oil production.)

```{r}
t_yview <- nrow(yview)
q_yview <- ncol(yview)
p_yview <- 2
T_yview <- t_yview - p_yview
```

There are 
`r q_yview` series and for each series
`r t_yview` monthly observations.
To visualize the data,
the visual model will use a VAR model of order `r p_yview`.

The next chunk of code generates the strips.
The code starts by transposing the matrix of observations:
```{r}
Uhat <- t(yview)
Uhat[, 1:4]
```
Again for visualizing the data,
the length of the blocks is chosen to be short:
```{r}
blen <- 4
nblocks <- ceiling((t_yview - p_yview) / blen)
```

This means that there will be `ceiling((t_yview - p_yview) / len)` blocks,
which amounts to `r nblocks` in this case.
And the strip of estimated innovations will have length `r nblocks * blen`,
which is greater than `r t_yview`.

The next code block 
allocates space to hold the time series of bootstrap innovations,
draws an initial block, and
builds up the remaining bootstrap innovations.
```{r}
set.seed(676)
rUtilde <- matrix(0, nrow = q_yview, ncol = nblocks * blen)

for (b in 0:(nblocks - 1)) {
  # draw over integers 1,...,T - blen + 1
  bupos <- ceiling(runif(1) * ((t_yview - p_yview) - blen + 1))
  # indexes for allocating rUtilde
  indlo <- b * blen + 1
  indhi <- b * blen + blen
  rUtilde[, indlo:indhi] <- Uhat[, bupos:(bupos + blen - 1)]
}
```

The blocks are clearly visible:
```{r}
rUtilde[, 1:(blen + 1)]
```
and
```{r}
rUtilde[, (blen + 1):(blen + 1 + blen)]
```
```{r}
rUtilde[, (nblocks * blen - blen):(nblocks * blen)]
```

So far the code has generated $\left[ \widehat{u}_1^*, \dots, \widehat{u}_T^* \right]$.
The recentering scheme of @brueggemann_jentsch_trenkler_2016 
must be implemented to ensure $E^* \left[ u_t^* \right] = 0$,
where $E^*$ denotes expectation under the bootstrap probability measure.
The recentering rule is
$$
\begin{align*}
u_{j\ell + s}^* = \widehat{u}_{j\ell + s}^* - \frac{1}{T - \ell + 1} \sum_{r=0}^{T-\ell} \widehat{u}_{s+r},
\end{align*}
$$
for $s = 1, 2,\dots,\ell$ and $j=0,1,\dots,\text{number of blocks} - 1$.

```{r, include=FALSE}
check_ind <- vector(mode = "integer", length = nblocks * blen)
cnt <- 0
for (s in 1:blen) {
  for (j in 0:(nblocks - 1)) {
    cnt <- cnt + 1
    check_ind[cnt] <- j * blen + s
    print(check_ind[cnt])
  }
}
sort(check_ind)
```


# Application: global market for crude oil

```{r}
y_global_oil <- kilianLutkepohlCh12Figure12_5 |> 
  # mutate(check_oil_supply = detrendcl(oil_supply, tt = "constant")) |>   
  mutate(across(c(oil_supply, agg_demand, rpoil), \(x) detrendcl(x, tt = "constant"))) |> 
  rename(oilsupply = oil_supply,
         aggdemand = agg_demand) |> 
  select(-date) |> 
  as.matrix()

horizon <- 15

sol_global_oil <- olsvarc(y_global_oil, p = 24)
var_order_global_oil <- c("oilsupply", "aggdemand", "rpoil")
var_cumsum_global_oil <- c("response_shock_oilsupply_oilsupply", 
                           "response_shock_oilsupply_aggdemand",
                           "response_shock_oilsupply_rpoil")
negative_shocks_global_oil <- c("oilsupply")

# response_shock_names <- get_irf_names(v_names = var_order_global_oil)
# 
# negative_shocks_to_adjust <- vector(mode = "character")
# 
# stringr::str_detect(response_shock_names, paste0("_", negative_shocks_global_oil[1], "$"))
# 
# for (ns in negative_shocks_global_oil) {
#       ns_adj <- response_shock_names[stringr::str_detect(response_shock_names, paste0("_", ns, "$"))]
#       negative_shocks_to_adjust <- c(negative_shocks_to_adjust, ns_adj)
#       }

irf_global_oil <- irfvar(Ahat = sol_global_oil$Ahat, 
                        B0inv = t(chol(sol_global_oil$SIGMAhat)),
                        p = sol_global_oil$p, h = horizon, 
                        negative_shocks = negative_shocks_global_oil,
                        var_cumsum = var_cumsum_global_oil,
                        var_order = var_order_global_oil)

nrep <- 250
dat_irf_global_oil_mbb <- bootstrap_mbb(olsobj = sol_global_oil, 
                                        irfobj = irf_global_oil, 
                                        nrep = nrep, 
                                        blen = 36,
                                        bootstrap_seed = 676, 
                                        display_progress_bar = TRUE)
```

# Mechanics of building data recursively

There are $K$ time series and $K$ refers to the dimension of the VAR process.
The VAR process is of order $p$ and is referred to as a VAR($p$) model.

The code uses the recursion
$$
Y_t = \boldsymbol{\nu} + \mathbf{A} Y_{t-1} + U_t,
$$
where  $Y_t = \left( y_t^{\prime}, \dots,y_{t-p+1}^{\prime}\right)^{\prime}$ and

$$
\boldsymbol{\nu} \equiv 
\begin{bmatrix}
\nu \\
0 \\
\vdots \\
0
\end{bmatrix}, \quad
\mathbf{A} \equiv 
\begin{bmatrix}
A_1    & A_2 & \cdots & A_{p-1} & A_p \\
I_K    & 0   & \cdots & 0       & 0   \\
0      & I_K &        & 0       & 0   \\
\vdots &     & \ddots & \vdots  & 0   \\
0      & 0   & \cdots & I_K     & 0
\end{bmatrix}, \text{ and }
U_t \equiv 
\begin{bmatrix}
u_t \\
0 \\
\vdots \\
0
\end{bmatrix}
$$

In other words, the VAR($p$) process is written as a VAR($1$) process.

The matrix $\mathbf{A}$ is referred to as the *companion matrix* of the VAR($p$) process.

How is the process started off?
In other words, 

Recall the visual dataset:
```{r}
head(yview)
```

The least-squares procedure 
```{r}
X_yview <- t(as.matrix(yview))
Y_yview <- X[, (p_yview + 1):t_yview]
# Create Z matrix by row-binding a matrix below,
# starting with vector of ones
Z_yview <- matrix(1, nrow = 1, ncol = T_yview)
for (i in 1:p_yview) {
  Z_yview <- rbind(Z_yview, X_yview[, (p_yview + 1 - i):(t_yview - i)])
}
```



# References
